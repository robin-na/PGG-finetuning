{
  "timestamp": "2601300930",
  "output_root": "/Users/robinna/Documents/projects/MultiAgent_LLM/PGG-finetuning/output",
  "analysis_output_root": "/Users/robinna/Documents/projects/MultiAgent_LLM/PGG-finetuning/analysis_output_Robin",
  "human_rounds": "/Users/robinna/Documents/projects/MultiAgent_LLM/PGG-finetuning/data/raw_data/validation_wave/player-rounds.csv",
  "human_configs": "/Users/robinna/Documents/projects/MultiAgent_LLM/PGG-finetuning/data/processed_data/df_analysis_val.csv",
  "sim_include_all": true,
  "sim_filters": {},
  "sim_models": [
    {
      "key": "no_reasoning",
      "label": "No reasoning",
      "include_reasoning": false
    },
    {
      "key": "with_reasoning",
      "label": "With reasoning",
      "include_reasoning": true
    }
  ],
  "metrics": [
    "mean_contribution_rate",
    "punishment_rate",
    "reward_rate",
    "normalized_efficiency"
  ],
  "variance_metrics": [
    "mean_contribution_rate",
    "punishment_rate",
    "reward_rate"
  ],
  "notes": "RMSE plotted per model with bootstrap standard deviation across configs for error bars. Metric mean plots compare both simulation variants against human means with human standard deviation error bars. Variance plots show across-player variance in each config, with aggregate means summarized separately."
}