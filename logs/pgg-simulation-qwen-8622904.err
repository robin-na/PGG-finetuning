/home/robinna/.conda/envs/llm_conda/lib/python3.9/contextlib.py:87: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:05,  1.98it/s]Loading checkpoint shards:  17%|█▋        | 2/12 [00:00<00:02,  3.75it/s]Loading checkpoint shards:  25%|██▌       | 3/12 [00:00<00:01,  5.23it/s]Loading checkpoint shards:  33%|███▎      | 4/12 [00:00<00:01,  6.43it/s]Loading checkpoint shards:  42%|████▏     | 5/12 [00:00<00:00,  7.31it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:01<00:00,  8.00it/s]Loading checkpoint shards:  58%|█████▊    | 7/12 [00:01<00:00,  8.53it/s]Loading checkpoint shards:  67%|██████▋   | 8/12 [00:01<00:00,  8.91it/s]Loading checkpoint shards:  75%|███████▌  | 9/12 [00:01<00:00,  9.19it/s]Loading checkpoint shards:  83%|████████▎ | 10/12 [00:01<00:00,  9.38it/s]Loading checkpoint shards:  92%|█████████▏| 11/12 [00:01<00:00,  9.53it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:01<00:00,  7.86it/s]
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 13; retrying with reduced chunk size 6.
  warnings.warn(
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 6; retrying with reduced chunk size 3.
  warnings.warn(
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 13; retrying with reduced chunk size 6.
  warnings.warn(
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 10; retrying with reduced chunk size 5.
  warnings.warn(
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 5; retrying with reduced chunk size 2.
  warnings.warn(
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 6; retrying with reduced chunk size 3.
  warnings.warn(
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 6; retrying with reduced chunk size 3.
  warnings.warn(
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 12; retrying with reduced chunk size 6.
  warnings.warn(
/orcd/home/002/robinna/PGG-finetuning/Simulation_robin/llm_client.py:269: UserWarning: CUDA OOM during generation with batch size 6; retrying with reduced chunk size 3.
  warnings.warn(
[2026-02-01T16:39:19.007] error: *** JOB 8622904 ON node3301 CANCELLED AT 2026-02-01T16:39:19 DUE TO TIME LIMIT ***
