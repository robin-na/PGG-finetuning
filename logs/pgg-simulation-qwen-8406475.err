/home/robinna/.conda/envs/llm_conda/lib/python3.9/contextlib.py:87: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/12 [00:00<?, ?it/s]Loading checkpoint shards:   8%|▊         | 1/12 [00:00<00:01,  6.36it/s]Loading checkpoint shards:  50%|█████     | 6/12 [00:00<00:00, 24.43it/s]Loading checkpoint shards:  92%|█████████▏| 11/12 [00:00<00:00, 31.71it/s]Loading checkpoint shards: 100%|██████████| 12/12 [00:00<00:00, 29.74it/s]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
